{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caa541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54998fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVRLogReg = joblib.load('OneVsRestLogisticRegression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e8ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_wrong_words = {\n",
    "    'fucksex': 'fuck sex',\n",
    "    'yourselfgo': 'your self ego',\n",
    "    'bcoz': 'because',\n",
    "    'bc': 'because',\n",
    "    'deneid': 'denied',\n",
    "    '\\u200e': '',\n",
    "    'wriminalwar': 'criminal war',\n",
    "    'Pathectic': 'pathetic',\n",
    "    'POLITCAL': 'political',\n",
    "    'talk2me': 'talk to me',\n",
    "    'shitfuck': 'shift fuck',\n",
    "    'BabyWhat': 'baby what',\n",
    "    'Sockpuppetry': 'sock puppetry',\n",
    "    'Bastered': 'bastard',\n",
    "    'PHILIPPINESLONG': 'philippines long',\n",
    "    'SuPeRTR0LL': 'supertroll',\n",
    "    'FUCKBAGS': 'fuck bags',\n",
    "    'peNis': 'penis',\n",
    "    'pensnsnnienSNsn': 'penis',\n",
    "    'pneis': 'penis', \n",
    "    'FooL': 'fool',\n",
    "    'pennnis': 'penis',\n",
    "    'PenIS': 'penis',\n",
    "    'itsuck': 'it suck',\n",
    "    'deletionist': 'delete',\n",
    "    'ReSPeCT': 'respect',\n",
    "    'stuipd' : 'stupid',\n",
    "    '@sshole': 'asshole',\n",
    "    'mf': 'mother fucker',\n",
    "    'b@stard': 'bastard',\n",
    "    's0n': 'son',\n",
    "    'b!tch': 'bitch'\n",
    "}\n",
    "\n",
    "def clean_wrong_spell_words(text, mapping):\n",
    "    for word in mapping:\n",
    "        text = text.replace(word, mapping[word])\n",
    "    return text\n",
    "\n",
    "def clean_html(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def clean_punc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keep_alpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def remove_special(cleaned):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',cleaned)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    cleaned = cleaned.lower()\n",
    "    return cleaned\n",
    "\n",
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\", \n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\", \n",
    "    \"'cause\": \"because\", \n",
    "    \"could've\": \"could have\", \n",
    "    \"couldn't\": \"could not\", \n",
    "    \"didn't\": \"did not\",  \n",
    "    \"doesn't\": \"does not\", \n",
    "    \"don't\": \"do not\", \n",
    "    \"hadn't\": \"had not\", \n",
    "    \"hasn't\": \"has not\", \n",
    "    \"haven't\": \"have not\", \n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\", \n",
    "    \"he's\": \"he is\", \n",
    "    \"how'd\": \"how did\", \n",
    "    \"how'd'y\": \"how do you\", \n",
    "    \"how'll\": \"how will\", \n",
    "    \"how's\": \"how is\",  \n",
    "    \"I'd\": \"I would\", \n",
    "    \"I'd've\": \"I would have\", \n",
    "    \"I'll\": \"I will\", \n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\", \n",
    "    \"I've\": \"I have\", \n",
    "    \"i'd\": \"i would\", \n",
    "    \"i'd've\": \"i would have\", \n",
    "    \"i'll\": \"i will\",  \n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\", \n",
    "    \"i've\": \"i have\", \n",
    "    \"isn't\": \"is not\", \n",
    "    \"it'd\": \"it would\", \n",
    "    \"it'd've\": \"it would have\", \n",
    "    \"it'll\": \"it will\", \"it'll've\": \n",
    "    \"it will have\",\"it's\": \"it is\", \n",
    "    \"let's\": \"let us\", \n",
    "    \"ma'am\": \"madam\", \n",
    "    \"mayn't\": \"may not\", \n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\", \n",
    "    \"must've\": \"must have\", \n",
    "    \"mustn't\": \"must not\", \n",
    "    \"mustn't've\": \"must not have\", \n",
    "    \"needn't\": \"need not\", \n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\", \n",
    "    \"oughtn't\": \"ought not\", \n",
    "    \"oughtn't've\": \"ought not have\", \n",
    "    \"shan't\": \"shall not\", \n",
    "    \"sha'n't\": \"shall not\", \n",
    "    \"shan't've\": \"shall not have\", \n",
    "    \"she'd\": \"she would\", \n",
    "    \"she'd've\": \"she would have\", \n",
    "    \"she'll\": \"she will\", \n",
    "    \"she'll've\": \"she will have\", \n",
    "    \"she's\": \"she is\", \n",
    "    \"should've\": \"should have\", \n",
    "    \"shouldn't\": \"should not\", \n",
    "    \"shouldn't've\": \"should not have\", \n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\", \n",
    "    \"this's\": \"this is\",\n",
    "    \"that'd\": \"that would\", \n",
    "    \"that'd've\": \"that would have\", \n",
    "    \"that's\": \"that is\", \n",
    "    \"there'd\": \"there would\", \n",
    "    \"there'd've\": \"there would have\", \n",
    "    \"there's\": \"there is\", \n",
    "    \"here's\": \"here is\",\n",
    "    \"they'd\": \"they would\", \n",
    "    \"they'd've\": \"they would have\", \n",
    "    \"they'll\": \"they will\", \n",
    "    \"they'll've\": \"they will have\", \n",
    "    \"they're\": \"they are\", \n",
    "    \"they've\": \"they have\", \n",
    "    \"to've\": \"to have\", \n",
    "    \"wasn't\": \"was not\", \n",
    "    \"we'd\": \"we would\", \n",
    "    \"we'd've\": \"we would have\", \n",
    "    \"we'll\": \"we will\", \n",
    "    \"we'll've\": \"we will have\", \n",
    "    \"we're\": \"we are\", \n",
    "    \"we've\": \"we have\", \n",
    "    \"weren't\": \"were not\", \n",
    "    \"what'll\": \"what will\", \n",
    "    \"what'll've\": \"what will have\", \n",
    "    \"what're\": \"what are\",  \n",
    "    \"what's\": \"what is\", \n",
    "    \"what've\": \"what have\", \n",
    "    \"when's\": \"when is\", \n",
    "    \"when've\": \"when have\", \n",
    "    \"where'd\": \"where did\", \n",
    "    \"where's\": \"where is\", \n",
    "    \"where've\": \"where have\", \n",
    "    \"who'll\": \"who will\", \n",
    "    \"who'll've\": \"who will have\", \n",
    "    \"who's\": \"who is\", \n",
    "    \"who've\": \"who have\", \n",
    "    \"why's\": \"why is\", \n",
    "    \"why've\": \"why have\", \n",
    "    \"will've\": \"will have\", \n",
    "    \"won't\": \"will not\", \n",
    "    \"won't've\": \"will not have\", \n",
    "    \"would've\": \"would have\", \n",
    "    \"wouldn't\": \"would not\", \n",
    "    \"wouldn't've\": \"would not have\", \n",
    "    \"y'all\": \"you all\", \n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\", \n",
    "    \"you'd've\": \"you would have\", \n",
    "    \"you'll\": \"you will\", \n",
    "    \"you'll've\": \"you will have\", \n",
    "    \"you're\": \"you are\", \n",
    "    \"you've\": \"you have\" }\n",
    "def remove_contractions(text, mapping):\n",
    "    for word in mapping:\n",
    "        text = text.replace(word, mapping[word])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a2087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    cleaned_text = \"\"\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            cleaned_text += word + ' '\n",
    "    return cleaned_text.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c196f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    for i in range(len(string)):\n",
    "        string[i] = remove_contractions(string[i], contraction_mapping)\n",
    "        string[i] = clean_wrong_spell_words(string[i], map_wrong_words)\n",
    "        string[i] = clean_html(string[i])\n",
    "        string[i] = clean_punc(string[i])\n",
    "        string[i] = keep_alpha(string[i])\n",
    "        string[i] = remove_stopwords(string[i])\n",
    "        string[i] = remove_special(string[i])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81869ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvid = joblib.load('TextPreprocessingAndVectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc1dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_toxicity(user_input):\n",
    "    return OVRLogReg.predict_proba(tfvid.transform(clean_text(user_input))) if type(user_input) is list else OVRLogReg.predict_proba(tfvid.transform(clean_text([str(user_input)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c839b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecf3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
